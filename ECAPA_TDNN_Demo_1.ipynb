{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ05OIcm2V/QgT2Ji3R5yA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya1331/SER-notebooks/blob/main/ECAPA_TDNN_Demo_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q yt-dlp"
      ],
      "metadata": {
        "id": "7uTx4-QF408r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to4xCy-G4Ech"
      },
      "outputs": [],
      "source": [
        "print(\"Installing packages...\")\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q torch==2.4.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q yt-dlp librosa soundfile matplotlib seaborn scikit-learn speechbrain\n",
        "\n",
        "print(\"\\n✓ Installation complete!\")\n",
        "print(\"\\n⚠️ IMPORTANT: Go to Runtime > Restart runtime\")\n",
        "print(\"Then run the main code in the next cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ All imports successful!\\n\")\n",
        "\n",
        "def download_youtube_audio(url: str, output_path: str = \"./audio\") -> str:\n",
        "    import yt_dlp\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav'}],\n",
        "        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),\n",
        "        'quiet': True,\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=True)\n",
        "        filename = ydl.prepare_filename(info)\n",
        "        audio_file = filename.rsplit('.', 1)[0] + '.wav'\n",
        "    return audio_file\n",
        "\n",
        "class SpeakerVerificationSystem:\n",
        "    def __init__(self):\n",
        "        from speechbrain.pretrained import EncoderClassifier\n",
        "        print(\"Loading ECAPA-TDNN model...\")\n",
        "        self.classifier = EncoderClassifier.from_hparams(\n",
        "            source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "            savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "        )\n",
        "        self.speaker_name = None\n",
        "        print(\"✓ Model loaded!\\n\")\n",
        "\n",
        "    def extract_embedding(self, audio_path: str) -> np.ndarray:\n",
        "        signal, sr = torchaudio.load(audio_path)\n",
        "        if sr != 16000:\n",
        "            signal = torchaudio.transforms.Resample(sr, 16000)(signal)\n",
        "        with torch.no_grad():\n",
        "            embedding = self.classifier.encode_batch(signal)\n",
        "        return embedding.squeeze().cpu().numpy()\n",
        "\n",
        "    def enroll_speaker(self, audio_files: List[str], speaker_name: str):\n",
        "        print(f\"Enrolling: {speaker_name}\")\n",
        "        self.speaker_name = speaker_name\n",
        "        embeddings = [self.extract_embedding(f) for f in audio_files]\n",
        "        self.enrollment_embedding = np.mean(embeddings, axis=0)\n",
        "        print(f\"✓ Enrolled with {len(audio_files)} samples\\n\")\n",
        "\n",
        "    def verify_speaker(self, test_audio: str, threshold: float = 0.25):\n",
        "        test_emb = self.extract_embedding(test_audio)\n",
        "        similarity = cosine_similarity(\n",
        "            self.enrollment_embedding.reshape(1, -1),\n",
        "            test_emb.reshape(1, -1)\n",
        "        )[0][0]\n",
        "        return {\n",
        "            'speaker_name': self.speaker_name,\n",
        "            'similarity': float(similarity),\n",
        "            'score': float(similarity * 100),\n",
        "            'verified': similarity > threshold,\n",
        "            'threshold': threshold,\n",
        "            'confidence': 'HIGH' if abs(similarity - threshold) > 0.15 else 'MEDIUM' if abs(similarity - threshold) > 0.08 else 'LOW'\n",
        "        }\n",
        "\n",
        "def split_audio_into_segments(audio_file: str, segment_duration: int = 10, output_dir: str = \"./segments\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    audio, sr = librosa.load(audio_file, sr=16000)\n",
        "    segment_length = segment_duration * sr\n",
        "    segments = []\n",
        "    for i in range(0, len(audio), segment_length):\n",
        "        segment = audio[i:i+segment_length]\n",
        "        if len(segment) >= sr * 3:\n",
        "            segment_file = os.path.join(output_dir, f\"segment_{i//segment_length:03d}.wav\")\n",
        "            sf.write(segment_file, segment, sr)\n",
        "            segments.append(segment_file)\n",
        "    return segments\n",
        "\n",
        "def visualize_verification_results(results):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Speaker Verification - ECAPA-TDNN', fontsize=16, fontweight='bold')\n",
        "\n",
        "    scores = [r['score'] for r in results]\n",
        "    similarities = [r['similarity'] for r in results]\n",
        "    verified = [r['verified'] for r in results]\n",
        "\n",
        "    axes[0, 0].bar(range(len(scores)), scores, color=['green' if v else 'red' for v in verified], alpha=0.7)\n",
        "    axes[0, 0].axhline(y=results[0]['threshold']*100, color='orange', linestyle='--')\n",
        "    axes[0, 0].set_title('Verification Scores')\n",
        "\n",
        "    axes[0, 1].hist(similarities, bins=15, color='skyblue', edgecolor='black')\n",
        "    axes[0, 1].set_title('Similarity Distribution')\n",
        "\n",
        "    verified_count = sum(verified)\n",
        "    axes[1, 0].pie([verified_count, len(verified)-verified_count],\n",
        "                   labels=['Verified', 'Failed'], colors=['green', 'red'], autopct='%1.1f%%')\n",
        "\n",
        "    conf_counts = {}\n",
        "    for r in results:\n",
        "        conf_counts[r['confidence']] = conf_counts.get(r['confidence'], 0) + 1\n",
        "    axes[1, 1].bar(conf_counts.keys(), conf_counts.values())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nVerified: {verified_count}/{len(results)} ({verified_count/len(results)*100:.1f}%)\")\n",
        "    print(f\"Avg Score: {np.mean(scores):.2f}\")\n",
        "\n",
        "def run_speaker_verification_demo(youtube_urls, speaker_name=\"Ranveer Allahbadia\", num_enrollment=3):\n",
        "    print(\"=\"*60)\n",
        "    print(\"SPEAKER VERIFICATION DEMO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    audio_files = []\n",
        "    for i, url in enumerate(youtube_urls[:6]):\n",
        "        print(f\"\\nDownloading {i+1}/6...\")\n",
        "        try:\n",
        "            audio_files.append(download_youtube_audio(url))\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    all_segments = []\n",
        "    for audio_file in audio_files:\n",
        "        all_segments.extend(split_audio_into_segments(audio_file))\n",
        "\n",
        "    verifier = SpeakerVerificationSystem()\n",
        "    verifier.enroll_speaker(all_segments[:num_enrollment], speaker_name)\n",
        "\n",
        "    results = []\n",
        "    for seg in all_segments[num_enrollment:num_enrollment+10]:\n",
        "        results.append(verifier.verify_speaker(seg))\n",
        "\n",
        "    visualize_verification_results(results)\n",
        "    return verifier, results\n",
        "\n",
        "YOUTUBE_URLS = [\n",
        "    \"https://youtu.be/e-sycEw4gyc\",\n",
        "    \"https://youtu.be/OcISVEh1jyw\",\n",
        "    \"https://youtu.be/8kS99Dqj6us\",\n",
        "    \"https://youtu.be/Mwpsr1iHStY\",\n",
        "    \"https://youtu.be/q3k8Ax8gBAI\",\n",
        "    \"https://youtu.be/M7x6A9hMeUo\",\n",
        "]\n",
        "\n",
        "print(\"Run: verifier, results = run_speaker_verification_demo(YOUTUBE_URLS)\")"
      ],
      "metadata": {
        "id": "BVaYUXE64q_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verifier, results = run_speaker_verification_demo(YOUTUBE_URLS)"
      ],
      "metadata": {
        "id": "cxCSr2Uy44Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/ecapa_demo_1.ipynb\", \"r\") as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "nb[\"metadata\"].pop(\"widgets\", None)\n",
        "\n",
        "with open(\"/content/ecapa_demo_1_clean.ipynb\", \"w\") as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"Clean notebook saved\")\n"
      ],
      "metadata": {
        "id": "b3RMZvq2Kr42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"ecapa_demo_1.ipynb\", \"r\") as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    nb[\"metadata\"].pop(\"widgets\")\n",
        "\n",
        "with open(\"ecapa_demo_1.ipynb\", \"w\") as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"Clean notebook saved\")\n"
      ],
      "metadata": {
        "id": "kleDPql7KX0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD4rxz7v14eL9R8EegpOUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya1331/SER-notebooks/blob/main/Call_Score_Demo_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook scores interview calls using only speaker diarization data (no transcripts).\n",
        "\n",
        "It infers roles, computes conversation metrics, and produces a 0-100 call quality score."
      ],
      "metadata": {
        "id": "yBdwR4Oq5-Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if needed (usually pre-installed in Colab)\n",
        "# !pip install numpy\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Tuple, Any\n",
        "\n",
        "print(\"‚úì Libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj5YRbjz55ol",
        "outputId": "828aef6a-49ce-41d9-a38c-6073ac0d05c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Libraries imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_diarization(filepath: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load diarization from JSON or RTTM-like text file.\n",
        "\n",
        "    Supports multiple formats:\n",
        "    - JSON: {\"segments\": [...]} or direct list\n",
        "    - RTTM: Space-separated text format\n",
        "\n",
        "    Returns list of segments with speaker, start, end times\n",
        "    \"\"\"\n",
        "    segments = []\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            # Peek at first character to detect format\n",
        "            first_char = f.read(1)\n",
        "            f.seek(0)  # Reset file pointer\n",
        "\n",
        "            # JSON format detection\n",
        "            if first_char == '{' or first_char == '[':\n",
        "                data = json.load(f)\n",
        "\n",
        "                # Handle wrapped JSON ({\"segments\": [...]})\n",
        "                if isinstance(data, dict):\n",
        "                    data = data.get('segments', data.get('results', []))\n",
        "\n",
        "                # Extract segments with flexible key names\n",
        "                for item in data:\n",
        "                    seg = {}\n",
        "                    # Try multiple possible key names for speaker\n",
        "                    seg['speaker'] = item.get('speaker', item.get('speaker_id', item.get('label', 'UNKNOWN')))\n",
        "                    # Try multiple possible key names for start time\n",
        "                    seg['start'] = float(item.get('start', item.get('start_time', item.get('begin', 0))))\n",
        "                    # Try multiple possible key names for end time\n",
        "                    seg['end'] = float(item.get('end', item.get('end_time', item.get('finish', seg['start']))))\n",
        "                    segments.append(seg)\n",
        "\n",
        "            # RTTM text format\n",
        "            else:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    # Skip empty lines and comments\n",
        "                    if not line or line.startswith('#'):\n",
        "                        continue\n",
        "\n",
        "                    parts = line.split()\n",
        "                    # Ensure minimum required fields\n",
        "                    if len(parts) >= 4:\n",
        "                        seg = {\n",
        "                            # RTTM format: SPEAKER file 1 start duration <NA> <NA> speaker_id\n",
        "                            'speaker': parts[0] if not parts[0].startswith('SPEAKER') else parts[7] if len(parts) > 7 else parts[0],\n",
        "                            'start': float(parts[3] if parts[0].startswith('SPEAKER') else parts[1]),\n",
        "                            # Calculate end from start + duration\n",
        "                            'end': float(parts[3]) + float(parts[4]) if parts[0].startswith('SPEAKER') and len(parts) > 4 else float(parts[2])\n",
        "                        }\n",
        "                        segments.append(seg)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Load error: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Filter invalid segments (end must be after start)\n",
        "    segments = [s for s in segments if s['end'] > s['start']]\n",
        "    # Sort chronologically\n",
        "    segments.sort(key=lambda x: x['start'])\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Test the loader\n",
        "print(\"‚úì Data loading function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibWwbt846EdD",
        "outputId": "cd37346d-4d64-4cf7-a127-a149f7b91e26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Data loading function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_speakers(segments: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Map speaker IDs to standardized SPEAKER_0 and SPEAKER_1.\n",
        "\n",
        "    If more than 2 speakers detected:\n",
        "    - Keep the 2 speakers with most total speaking time\n",
        "    - Discard others as noise/crosstalk\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return []\n",
        "\n",
        "    # Get unique speaker IDs\n",
        "    unique_speakers = sorted(set(s['speaker'] for s in segments))\n",
        "\n",
        "    # Handle case with >2 speakers\n",
        "    if len(unique_speakers) > 2:\n",
        "        # Calculate total speaking time per speaker\n",
        "        speaker_times = defaultdict(float)\n",
        "        for s in segments:\n",
        "            speaker_times[s['speaker']] += s['end'] - s['start']\n",
        "\n",
        "        # Keep top 2 speakers by speaking time\n",
        "        unique_speakers = sorted(\n",
        "            speaker_times.keys(),\n",
        "            key=lambda x: speaker_times[x],\n",
        "            reverse=True\n",
        "        )[:2]\n",
        "\n",
        "    # Create mapping: original_id -> SPEAKER_0/SPEAKER_1\n",
        "    speaker_map = {spk: f\"SPEAKER_{i}\" for i, spk in enumerate(unique_speakers)}\n",
        "\n",
        "    # Apply mapping to all segments\n",
        "    for seg in segments:\n",
        "        seg['speaker'] = speaker_map.get(seg['speaker'], 'SPEAKER_UNKNOWN')\n",
        "\n",
        "    # Remove segments from discarded speakers\n",
        "    return [s for s in segments if s['speaker'] != 'SPEAKER_UNKNOWN']\n",
        "\n",
        "print(\"‚úì Speaker normalization function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBpY1tZS6Klz",
        "outputId": "2fac3678-d40c-4144-98dd-274d8f6e7ee7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Speaker normalization function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_roles(segments: List[Dict]) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Infer who is interviewer vs candidate using heuristics:\n",
        "\n",
        "    Heuristics:\n",
        "    1. Interviewer usually speaks first (opens the call)\n",
        "    2. Interviewer typically has more turn-taking (asks questions)\n",
        "\n",
        "    Returns: (interviewer_id, candidate_id)\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return 'SPEAKER_0', 'SPEAKER_1'\n",
        "\n",
        "    # Heuristic 1: First speaker is likely interviewer\n",
        "    first_speaker = segments[0]['speaker']\n",
        "\n",
        "    # Heuristic 2: Count turn transitions per speaker\n",
        "    turn_counts = defaultdict(int)\n",
        "    prev_speaker = None\n",
        "\n",
        "    for seg in segments:\n",
        "        # New turn detected when speaker changes\n",
        "        if seg['speaker'] != prev_speaker:\n",
        "            turn_counts[seg['speaker']] += 1\n",
        "            prev_speaker = seg['speaker']\n",
        "\n",
        "    speakers = ['SPEAKER_0', 'SPEAKER_1']\n",
        "\n",
        "    # Edge case: only one speaker detected\n",
        "    if len(turn_counts) < 2:\n",
        "        return first_speaker, [s for s in speakers if s != first_speaker][0]\n",
        "\n",
        "    # Speaker with more turns is likely interviewer (asks questions)\n",
        "    more_turns_speaker = max(turn_counts, key=turn_counts.get)\n",
        "\n",
        "    # If both heuristics agree, high confidence\n",
        "    if first_speaker == more_turns_speaker:\n",
        "        interviewer = first_speaker\n",
        "    else:\n",
        "        # Tie-breaker: trust turn count over first-speaker\n",
        "        interviewer = more_turns_speaker\n",
        "\n",
        "    # Assign remaining speaker as candidate\n",
        "    candidate = [s for s in speakers if s != interviewer][0]\n",
        "\n",
        "    return interviewer, candidate\n",
        "\n",
        "print(\"‚úì Role inference function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lsm4G7y6PD1",
        "outputId": "090fe603-cdd0-447d-8ce2-c7e3a7bf748c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Role inference function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_talk_ratio(segments: List[Dict], interviewer: str, candidate: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate speaking time distribution.\n",
        "\n",
        "    Healthy range: Candidate speaks 40-60% of total time\n",
        "    - Too low (<30%): Candidate not engaged\n",
        "    - Too high (>70%): Candidate dominating/rambling\n",
        "    \"\"\"\n",
        "    # Sum duration for each speaker\n",
        "    interviewer_time = sum(s['end'] - s['start'] for s in segments if s['speaker'] == interviewer)\n",
        "    candidate_time = sum(s['end'] - s['start'] for s in segments if s['speaker'] == candidate)\n",
        "\n",
        "    total_time = interviewer_time + candidate_time\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if total_time == 0:\n",
        "        return {'interviewer_time': 0, 'candidate_time': 0, 'candidate_ratio': 0}\n",
        "\n",
        "    return {\n",
        "        'interviewer_time': round(interviewer_time, 2),\n",
        "        'candidate_time': round(candidate_time, 2),\n",
        "        'candidate_ratio': round(candidate_time / total_time, 3)  # 0.0 to 1.0\n",
        "    }\n",
        "\n",
        "print(\"‚úì Talk ratio function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gd4CiAI6UiW",
        "outputId": "fb48c9ff-1242-46d1-8fe5-3955f6a95710"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Talk ratio function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "candidate_ratio = 0.45 ‚Üí Candidate spoke 45% of time (good balance)\n",
        "\n",
        "candidate_ratio = 0.20 ‚Üí Candidate spoke only 20% (red flag: disengaged)\n",
        "\n",
        "candidate_ratio = 0.80 ‚Üí Candidate spoke 80% (yellow flag: over-talking)"
      ],
      "metadata": {
        "id": "ip9dAkYZ6byT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_turn_balance(segments: List[Dict], interviewer: str, candidate: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate turn-taking balance.\n",
        "\n",
        "    Healthy conversation: Balanced back-and-forth exchange\n",
        "    Balance score: 1.0 = perfect balance, 0.0 = one-sided\n",
        "    \"\"\"\n",
        "    turns = []\n",
        "    prev_speaker = None\n",
        "\n",
        "    # Extract turn sequence: [INTERVIEWER, CANDIDATE, INTERVIEWER, ...]\n",
        "    for seg in segments:\n",
        "        if seg['speaker'] != prev_speaker:\n",
        "            turns.append(seg['speaker'])\n",
        "            prev_speaker = seg['speaker']\n",
        "\n",
        "    # Edge case: too few turns\n",
        "    if len(turns) < 2:\n",
        "        return {\n",
        "            'total_turns': len(turns),\n",
        "            'interviewer_turns': 0,\n",
        "            'candidate_turns': 0,\n",
        "            'balance_score': 0\n",
        "        }\n",
        "\n",
        "    interviewer_turns = turns.count(interviewer)\n",
        "    candidate_turns = turns.count(candidate)\n",
        "    total_turns = len(turns)\n",
        "\n",
        "    # Calculate balance score\n",
        "    # Perfect balance: interviewer_turns == candidate_turns\n",
        "    # Formula: 1 - (absolute difference / total turns)\n",
        "    balance_score = 1.0 - abs(interviewer_turns - candidate_turns) / total_turns\n",
        "\n",
        "    return {\n",
        "        'total_turns': total_turns,\n",
        "        'interviewer_turns': interviewer_turns,\n",
        "        'candidate_turns': candidate_turns,\n",
        "        'balance_score': round(balance_score, 3)  # 0.0 to 1.0\n",
        "    }\n",
        "\n",
        "print(\"‚úì Turn balance function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN0G2Zh46fEG",
        "outputId": "8cb38f37-0e9b-40b0-9786-c90dc1f5e98e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Turn balance function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_response_latency(segments: List[Dict], interviewer: str, candidate: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculate average time gap between interviewer finishing and candidate starting.\n",
        "\n",
        "    Measures candidate's response speed:\n",
        "    - <0.5s: Quick, engaged responses\n",
        "    - 0.5-1.5s: Normal thinking time\n",
        "    - >2s: Slow/hesitant (possible confusion or lack of preparation)\n",
        "    \"\"\"\n",
        "    latencies = []\n",
        "\n",
        "    # Find all interviewer ‚Üí candidate transitions\n",
        "    for i in range(len(segments) - 1):\n",
        "        if segments[i]['speaker'] == interviewer and segments[i + 1]['speaker'] == candidate:\n",
        "            # Gap = candidate_start - interviewer_end\n",
        "            gap = segments[i + 1]['start'] - segments[i]['end']\n",
        "\n",
        "            # Only count positive gaps (negative = overlap/interruption)\n",
        "            if gap >= 0:\n",
        "                latencies.append(gap)\n",
        "\n",
        "    if not latencies:\n",
        "        return {'avg_latency': 0, 'latency_count': 0}\n",
        "\n",
        "    return {\n",
        "        'avg_latency': round(np.mean(latencies), 3),  # Average in seconds\n",
        "        'latency_count': len(latencies)  # Number of transitions measured\n",
        "    }\n",
        "\n",
        "print(\"‚úì Response latency function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBTpbyvT6l02",
        "outputId": "59f5fc12-7bab-40cf-8467-65efd61b9d07"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Response latency function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_overlaps(segments: List[Dict]) -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Count overlapping speech events.\n",
        "\n",
        "    Overlap: Any simultaneous speech by both speakers\n",
        "    Interruption: Overlap starting >0.5s before previous speaker finishes\n",
        "\n",
        "    High overlap rate suggests:\n",
        "    - Poor connection (audio delay)\n",
        "    - Aggressive communication style\n",
        "    - Excitement/engagement (context-dependent)\n",
        "    \"\"\"\n",
        "    overlaps = 0\n",
        "    interruptions = 0\n",
        "\n",
        "    # Compare each segment with all following segments\n",
        "    for i in range(len(segments) - 1):\n",
        "        for j in range(i + 1, len(segments)):\n",
        "            # Stop if segment j starts after segment i ends\n",
        "            if segments[j]['start'] >= segments[i]['end']:\n",
        "                break\n",
        "\n",
        "            # Check for overlap between different speakers\n",
        "            if segments[i]['speaker'] != segments[j]['speaker']:\n",
        "                # Calculate overlap duration\n",
        "                overlap_duration = min(segments[i]['end'], segments[j]['end']) - segments[j]['start']\n",
        "\n",
        "                if overlap_duration > 0:\n",
        "                    overlaps += 1\n",
        "\n",
        "                    # Classify as interruption if overlap starts mid-speech\n",
        "                    # Threshold: 0.5s before previous speaker finishes\n",
        "                    if segments[j]['start'] < segments[i]['end'] - 0.5:\n",
        "                        interruptions += 1\n",
        "\n",
        "    return {\n",
        "        'total_overlaps': overlaps,\n",
        "        'interruptions': interruptions\n",
        "    }\n",
        "\n",
        "print(\"‚úì Overlap detection function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xugahw86o0S",
        "outputId": "89c504c9-5747-4883-cbdc-050e5806bb7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Overlap detection function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_call_score(metrics: Dict[str, Any]) -> int:\n",
        "    \"\"\"\n",
        "    Compute 0-100 call quality score using weighted metrics.\n",
        "\n",
        "    Scoring logic:\n",
        "    - Start at 100 points\n",
        "    - Deduct points for concerning patterns\n",
        "    - Add points for positive signals\n",
        "\n",
        "    Final score interpretation:\n",
        "    - 80-100: Excellent call quality\n",
        "    - 60-79: Good, minor issues\n",
        "    - 40-59: Fair, notable concerns\n",
        "    - 0-39: Poor call quality\n",
        "    \"\"\"\n",
        "    score = 100  # Start with perfect score\n",
        "\n",
        "    # --- TALK RATIO PENALTIES ---\n",
        "    talk_ratio = metrics['talk_ratio']['candidate_ratio']\n",
        "\n",
        "    if talk_ratio < 0.3:\n",
        "        score -= 20  # Severe: Candidate barely spoke\n",
        "    elif talk_ratio < 0.4:\n",
        "        score -= 10  # Moderate: Candidate under-engaged\n",
        "    elif talk_ratio > 0.7:\n",
        "        score -= 15  # Severe: Candidate dominating\n",
        "    elif talk_ratio > 0.6:\n",
        "        score -= 5   # Slight: Candidate talking a bit much\n",
        "\n",
        "    # --- TURN BALANCE ADJUSTMENT ---\n",
        "    balance = metrics['turn_balance']['balance_score']\n",
        "    # Scale balance score from 0-1 to -10 to +10 points\n",
        "    score += (balance - 0.5) * 20\n",
        "\n",
        "    # --- RESPONSE LATENCY PENALTIES ---\n",
        "    latency = metrics['response_latency']['avg_latency']\n",
        "\n",
        "    if latency > 2.0:\n",
        "        score -= 15  # Severe: Very slow responses\n",
        "    elif latency > 1.5:\n",
        "        score -= 8   # Moderate: Somewhat slow\n",
        "    elif latency < 0.3:\n",
        "        score += 5   # Bonus: Very quick, engaged responses\n",
        "\n",
        "    # --- OVERLAP/INTERRUPTION PENALTIES ---\n",
        "    overlaps = metrics['overlaps']['total_overlaps']\n",
        "    interruptions = metrics['overlaps']['interruptions']\n",
        "    total_turns = metrics['turn_balance']['total_turns']\n",
        "\n",
        "    if total_turns > 0:\n",
        "        # Calculate overlap rate relative to turn count\n",
        "        overlap_rate = overlaps / total_turns\n",
        "\n",
        "        if overlap_rate > 0.3:\n",
        "            score -= 20  # Severe: Chaotic conversation\n",
        "        elif overlap_rate > 0.2:\n",
        "            score -= 10  # Moderate: Frequent overlaps\n",
        "\n",
        "        # Additional penalty for interruptions\n",
        "        if interruptions > total_turns * 0.15:\n",
        "            score -= 10  # Too many interruptions\n",
        "\n",
        "    # Clamp score to 0-100 range\n",
        "    return max(0, min(100, int(score)))\n",
        "\n",
        "print(\"‚úì Score calculation function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKKfuAyo6riR",
        "outputId": "67b0fbf8-324b-4556-9d89-39d5fd79affb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Score calculation function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_call(diarization_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Complete end-to-end call scoring pipeline.\n",
        "\n",
        "    Steps:\n",
        "    1. Load diarization file\n",
        "    2. Normalize speaker IDs\n",
        "    3. Infer interviewer vs candidate roles\n",
        "    4. Compute all metrics\n",
        "    5. Calculate final score\n",
        "\n",
        "    Returns JSON with score and detailed metrics\n",
        "    \"\"\"\n",
        "    # Step 1: Load data\n",
        "    segments = load_diarization(diarization_path)\n",
        "\n",
        "    if not segments:\n",
        "        return {\n",
        "            'error': 'No valid segments found',\n",
        "            'call_score': 0,\n",
        "            'metrics': {}\n",
        "        }\n",
        "\n",
        "    # Step 2: Normalize speakers to SPEAKER_0 and SPEAKER_1\n",
        "    segments = normalize_speakers(segments)\n",
        "\n",
        "    if len(segments) < 2:\n",
        "        return {\n",
        "            'error': 'Insufficient segments for analysis',\n",
        "            'call_score': 0,\n",
        "            'metrics': {}\n",
        "        }\n",
        "\n",
        "    # Step 3: Infer roles\n",
        "    interviewer, candidate = infer_roles(segments)\n",
        "\n",
        "    # Step 4: Compute all metrics\n",
        "    metrics = {\n",
        "        'roles': {\n",
        "            'interviewer': interviewer,\n",
        "            'candidate': candidate\n",
        "        },\n",
        "        'talk_ratio': compute_talk_ratio(segments, interviewer, candidate),\n",
        "        'turn_balance': compute_turn_balance(segments, interviewer, candidate),\n",
        "        'response_latency': compute_response_latency(segments, interviewer, candidate),\n",
        "        'overlaps': compute_overlaps(segments)\n",
        "    }\n",
        "\n",
        "    # Step 5: Calculate final score\n",
        "    call_score = calculate_call_score(metrics)\n",
        "\n",
        "    return {\n",
        "        'call_score': call_score,\n",
        "        'metrics': metrics,\n",
        "        'segment_count': len(segments)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Main pipeline function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xElF8xi06urK",
        "outputId": "51970148-b0dc-4743-a352-e9c4ca1e5808"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Main pipeline function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample diarization file for testing\n",
        "sample_data = {\n",
        "    \"segments\": [\n",
        "        {\"speaker\": \"spk_0\", \"start\": 0.0, \"end\": 3.5},\n",
        "        {\"speaker\": \"spk_1\", \"start\": 3.8, \"end\": 8.2},\n",
        "        {\"speaker\": \"spk_0\", \"start\": 8.5, \"end\": 12.1},\n",
        "        {\"speaker\": \"spk_1\", \"start\": 12.4, \"end\": 18.7},\n",
        "        {\"speaker\": \"spk_0\", \"start\": 19.0, \"end\": 22.3},\n",
        "        {\"speaker\": \"spk_1\", \"start\": 22.5, \"end\": 30.2},\n",
        "        {\"speaker\": \"spk_0\", \"start\": 30.8, \"end\": 35.1},\n",
        "        {\"speaker\": \"spk_1\", \"start\": 35.3, \"end\": 42.6},\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Save to file\n",
        "with open('diarization.json', 'w') as f:\n",
        "    json.dump(sample_data, f, indent=2)\n",
        "\n",
        "print(\"‚úì Sample diarization file created: diarization.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_yMKqgI6uoU",
        "outputId": "b1becfba-7562-403e-add7-8d92db61ca49"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Sample diarization file created: diarization.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score the call\n",
        "diarization_file = 'diarization.json'\n",
        "result = score_call(diarization_file)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CALL SCORING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(result, indent=2))\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT5YxFgS61Ti",
        "outputId": "736ab980-b18c-40ef-da54-47ee9d8b22f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CALL SCORING RESULTS\n",
            "============================================================\n",
            "{\n",
            "  \"call_score\": 100,\n",
            "  \"metrics\": {\n",
            "    \"roles\": {\n",
            "      \"interviewer\": \"SPEAKER_0\",\n",
            "      \"candidate\": \"SPEAKER_1\"\n",
            "    },\n",
            "    \"talk_ratio\": {\n",
            "      \"interviewer_time\": 14.7,\n",
            "      \"candidate_time\": 25.7,\n",
            "      \"candidate_ratio\": 0.636\n",
            "    },\n",
            "    \"turn_balance\": {\n",
            "      \"total_turns\": 8,\n",
            "      \"interviewer_turns\": 4,\n",
            "      \"candidate_turns\": 4,\n",
            "      \"balance_score\": 1.0\n",
            "    },\n",
            "    \"response_latency\": {\n",
            "      \"avg_latency\": 0.25,\n",
            "      \"latency_count\": 4\n",
            "    },\n",
            "    \"overlaps\": {\n",
            "      \"total_overlaps\": 0,\n",
            "      \"interruptions\": 0\n",
            "    }\n",
            "  },\n",
            "  \"segment_count\": 8\n",
            "}\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and display individual metrics for easier interpretation\n",
        "if 'metrics' in result and result['metrics']:\n",
        "    print(\"\\nüìä DETAILED METRICS BREAKDOWN\\n\")\n",
        "\n",
        "    # Roles\n",
        "    roles = result['metrics']['roles']\n",
        "    print(f\"üë• Identified Roles:\")\n",
        "    print(f\"   Interviewer: {roles['interviewer']}\")\n",
        "    print(f\"   Candidate: {roles['candidate']}\\n\")\n",
        "\n",
        "    # Talk ratio\n",
        "    talk = result['metrics']['talk_ratio']\n",
        "    print(f\"üó£Ô∏è  Talk Ratio:\")\n",
        "    print(f\"   Interviewer time: {talk['interviewer_time']}s\")\n",
        "    print(f\"   Candidate time: {talk['candidate_time']}s\")\n",
        "    print(f\"   Candidate ratio: {talk['candidate_ratio']:.1%}\\n\")\n",
        "\n",
        "    # Turn balance\n",
        "    turns = result['metrics']['turn_balance']\n",
        "    print(f\"üîÑ Turn Balance:\")\n",
        "    print(f\"   Total turns: {turns['total_turns']}\")\n",
        "    print(f\"   Interviewer turns: {turns['interviewer_turns']}\")\n",
        "    print(f\"   Candidate turns: {turns['candidate_turns']}\")\n",
        "    print(f\"   Balance score: {turns['balance_score']:.2f}/1.00\\n\")\n",
        "\n",
        "    # Response latency\n",
        "    latency = result['metrics']['response_latency']\n",
        "    print(f\"‚è±Ô∏è  Response Latency:\")\n",
        "    print(f\"   Average: {latency['avg_latency']:.2f}s\")\n",
        "    print(f\"   Measured transitions: {latency['latency_count']}\\n\")\n",
        "\n",
        "    # Overlaps\n",
        "    overlap = result['metrics']['overlaps']\n",
        "    print(f\"üîÄ Overlaps:\")\n",
        "    print(f\"   Total overlaps: {overlap['total_overlaps']}\")\n",
        "    print(f\"   Interruptions: {overlap['interruptions']}\\n\")\n",
        "\n",
        "    # Final score\n",
        "    print(f\"üéØ FINAL SCORE: {result['call_score']}/100\")\n",
        "\n",
        "    # Score interpretation\n",
        "    score = result['call_score']\n",
        "    if score >= 80:\n",
        "        quality = \"Excellent ‚úÖ\"\n",
        "    elif score >= 60:\n",
        "        quality = \"Good ‚úì\"\n",
        "    elif score >= 40:\n",
        "        quality = \"Fair ‚ö†Ô∏è\"\n",
        "    else:\n",
        "        quality = \"Poor ‚ùå\"\n",
        "\n",
        "    print(f\"   Quality: {quality}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awynaOyQ64jd",
        "outputId": "03ef0bf1-b047-4e19-9c76-f879224774b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DETAILED METRICS BREAKDOWN\n",
            "\n",
            "üë• Identified Roles:\n",
            "   Interviewer: SPEAKER_0\n",
            "   Candidate: SPEAKER_1\n",
            "\n",
            "üó£Ô∏è  Talk Ratio:\n",
            "   Interviewer time: 14.7s\n",
            "   Candidate time: 25.7s\n",
            "   Candidate ratio: 63.6%\n",
            "\n",
            "üîÑ Turn Balance:\n",
            "   Total turns: 8\n",
            "   Interviewer turns: 4\n",
            "   Candidate turns: 4\n",
            "   Balance score: 1.00/1.00\n",
            "\n",
            "‚è±Ô∏è  Response Latency:\n",
            "   Average: 0.25s\n",
            "   Measured transitions: 4\n",
            "\n",
            "üîÄ Overlaps:\n",
            "   Total overlaps: 0\n",
            "   Interruptions: 0\n",
            "\n",
            "üéØ FINAL SCORE: 100/100\n",
            "   Quality: Excellent ‚úÖ\n"
          ]
        }
      ]
    }
  ]
}
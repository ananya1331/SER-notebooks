{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC/Te7KYI0H3c0KmOkcvnc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya1331/SER-notebooks/blob/main/Call_Score_Demo_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call Score : evaluating an agent's performance against predefined criteria\n",
        "\n",
        "1. How well the interviewer followed the process\n",
        "2. How effectively the conversation progressed\n",
        "3. How the candidate responded\n",
        "\n",
        "What to measure?\n",
        "- Talk Ratio\n",
        "- Response quality/Candidate responsiveness (Latency, Duration)\n",
        "- Structure Adherence\n",
        "\n",
        "Data needed:\n",
        "- Audio\n",
        "- Diarization Ouput\n",
        "- Timestamped Transcription\n",
        "- Sentiment Output"
      ],
      "metadata": {
        "id": "QvRJ22z5Q2AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "sFJ9Tr9pQ9q-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duration(seg):\n",
        "    return seg[\"end\"] - seg[\"start\"]\n",
        "\n",
        "def is_question(text):\n",
        "    text = text.lower().strip()\n",
        "    return (\n",
        "        text.endswith(\"?\")\n",
        "        or text.startswith((\"what\", \"why\", \"how\", \"can you\", \"could you\"))\n",
        "    )"
      ],
      "metadata": {
        "id": "44L-78qBRGaK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Talk Ratio Score : Measures conversation balance\n",
        "\n",
        "Cadidate Talk Ratio : R = Tc / T\n",
        "\n",
        "Scoring Function :\n",
        "                                        \n",
        "                                        100 if 0.55 ≤R ≤ 0.70\n",
        "\n",
        "    Talk Ratio Score        = {         70 if 0.40 ≤ R< 0.55 or 0.70 < R≤ 0.85\n",
        "\n",
        "                                        30 otherwise\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "57dGVd_pRLYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def talk_ratio_score(diarization):\n",
        "    times = defaultdict(float)\n",
        "\n",
        "    for seg in diarization:\n",
        "        times[seg[\"speaker\"]] += duration(seg)\n",
        "\n",
        "    interviewer = times.get(\"INTERVIEWER\", 0)\n",
        "    candidate = times.get(\"CANDIDATE\", 0)\n",
        "    total = interviewer + candidate\n",
        "\n",
        "    if total == 0:\n",
        "        return 0\n",
        "\n",
        "    ratio = candidate / total\n",
        "\n",
        "    if 0.55 <= ratio <= 0.70:\n",
        "        return 100\n",
        "    elif ratio < 0.40 or ratio > 0.85:\n",
        "        return 30\n",
        "    else:\n",
        "        return 70"
      ],
      "metadata": {
        "id": "HfJIBKyeRRfF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Candidate Responsiveness : Latency + answer quality"
      ],
      "metadata": {
        "id": "OKxPXs7YRWrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def candidate_responsiveness_score(transcript):\n",
        "    scores = []\n",
        "\n",
        "    for i in range(len(transcript) - 1):\n",
        "        curr = transcript[i]\n",
        "        nxt = transcript[i + 1]\n",
        "\n",
        "        if curr[\"speaker\"] == \"INTERVIEWER\" and is_question(curr[\"text\"]):\n",
        "            if nxt[\"speaker\"] == \"CANDIDATE\":\n",
        "                latency = nxt[\"start\"] - curr[\"end\"]\n",
        "                answer_len = nxt[\"end\"] - nxt[\"start\"]\n",
        "\n",
        "                latency_score = 100 if latency <= 2 else 60 if latency <= 5 else 30\n",
        "                duration_score = 100 if 10 <= answer_len <= 60 else 50\n",
        "\n",
        "                scores.append((latency_score + duration_score) / 2)\n",
        "\n",
        "    if not scores:\n",
        "        return 20\n",
        "\n",
        "    return int(sum(scores) / len(scores))"
      ],
      "metadata": {
        "id": "hM7ty5x4Rb2m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structure Adherence : Did the interviewer follow a sane flow?"
      ],
      "metadata": {
        "id": "9J4zv0gHRf_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def structure_adherence_score(transcript):\n",
        "    stages = {\n",
        "        \"intro\": False,\n",
        "        \"experience\": False,\n",
        "        \"problem\": False,\n",
        "        \"closing\": False\n",
        "    }\n",
        "\n",
        "    for turn in transcript:\n",
        "        text = turn[\"text\"].lower()\n",
        "\n",
        "        if \"introduce\" in text or \"background\" in text:\n",
        "            stages[\"intro\"] = True\n",
        "        if \"experience\" in text or \"worked on\" in text:\n",
        "            stages[\"experience\"] = True\n",
        "        if \"challenge\" in text or \"problem\" in text:\n",
        "            stages[\"problem\"] = True\n",
        "        if \"questions for me\" in text or \"next steps\" in text:\n",
        "            stages[\"closing\"] = True\n",
        "\n",
        "    return int((sum(stages.values()) / len(stages)) * 100)"
      ],
      "metadata": {
        "id": "lxQENvgjRlF9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Call Score = 0.40⋅TalkRatioScore + 0.35⋅CandidateResponsiveness + 0.25⋅StructureAdherence"
      ],
      "metadata": {
        "id": "tzAK2EjTRsMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_call_score(diarization, transcript):\n",
        "    scores = {\n",
        "        \"talk_ratio\": talk_ratio_score(diarization),\n",
        "        \"candidate_responsiveness\": candidate_responsiveness_score(transcript),\n",
        "        \"structure_adherence\": structure_adherence_score(transcript),\n",
        "    }\n",
        "\n",
        "    final_score = round(\n",
        "        0.4 * scores[\"talk_ratio\"] +\n",
        "        0.35 * scores[\"candidate_responsiveness\"] +\n",
        "        0.25 * scores[\"structure_adherence\"]\n",
        "    )\n",
        "\n",
        "    scores[\"final_call_score\"] = final_score\n",
        "    return scores"
      ],
      "metadata": {
        "id": "tqTl2B_ERoVN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example run with mock data"
      ],
      "metadata": {
        "id": "nlAwihzaR1Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diarization = [\n",
        "    {\"speaker\": \"INTERVIEWER\", \"start\": 0.0, \"end\": 10.0},\n",
        "    {\"speaker\": \"CANDIDATE\", \"start\": 10.2, \"end\": 45.0},\n",
        "    {\"speaker\": \"INTERVIEWER\", \"start\": 45.2, \"end\": 60.0},\n",
        "]\n",
        "\n",
        "transcript = [\n",
        "    {\"speaker\": \"INTERVIEWER\", \"start\": 0.0, \"end\": 10.0, \"text\": \"Can you introduce yourself?\"},\n",
        "    {\"speaker\": \"CANDIDATE\", \"start\": 10.2, \"end\": 45.0, \"text\": \"I have three years of experience working on backend systems.\"},\n",
        "    {\"speaker\": \"INTERVIEWER\", \"start\": 45.2, \"end\": 60.0, \"text\": \"What was the most challenging problem you solved?\"}\n",
        "]\n",
        "\n",
        "print(json.dumps(compute_call_score(diarization, transcript), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA8ZuuEkR3rv",
        "outputId": "e0998cdb-d91e-4a01-90e8-ab1b2b306b2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"talk_ratio\": 100,\n",
            "  \"candidate_responsiveness\": 100,\n",
            "  \"structure_adherence\": 75,\n",
            "  \"final_call_score\": 94\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}